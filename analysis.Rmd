---
title: "Analysis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Imports
```{r message=FALSE}
library(mgcv)
library(tidyverse)
library(caret)
library(mice)
library(quantreg)

df <- read.csv("data/train_simple.csv", stringsAsFactors = TRUE)

train_idx <- read.csv("data/X_train.csv")$X
train_df <- df[train_idx, ]
test_df <- df[-train_idx, ]
rm(df)
```

## Define metric
```{r}
mean_abs_err <- function(y_hat, y){
  sum(abs(y_hat - y)) / length(y_hat)
}
```

## Fit linear regression without imputing income
As lots of the incomes are zero, it makes sense to impute these, as employment status is a categorical variable anyway which accounts for those with no income. First we can get a baseline without imputing income.
```{r}
mod <- lm(total_claim_amount ~ vehicle_class + income +
             employment_status*monthly_premium_auto + 
             location_code*monthly_premium_auto, data = train_df)

y_hat <- predict(mod, newdata = test_df)

summary(mod)

mae <- mean_abs_err(y_hat, test_df$total_claim_amount)
print(paste("MAE of:", round(mae, 2)))

```
## Try imputing income variable
```{r results='hide'}
df_big <- read.csv("data/train.csv", stringsAsFactors = TRUE)
df_big <- df_big %>% select(-Country, -Customer)
df_big$Income[df_big$Income == 0] <- NA

imputations <- complete(mice(df_big, method = "pmm", seed=1))

train_df$income <- imputations$Income[train_idx]
test_df$income <- imputations$Income[-train_idx]
```

## Linear regression with "missing" income values imputed
```{r}
mod <- lm(total_claim_amount ~ vehicle_class + income +
             employment_status*monthly_premium_auto + 
             location_code*monthly_premium_auto, data = train_df)

y_hat <- predict(mod, newdata = test_df)

summary(mod)

mae <- mean_abs_err(y_hat, test_df$total_claim_amount)
print(paste("MAE of:", round(mae, 2)))
```
Doesn't seem to make much difference.

## GAM
Does using a GAM improve performance? Again using the data with imputed income (even though it probably doesn't make much difference).

```{r}
mod <- gam(total_claim_amount ~ employment_status + location_code + 
             vehicle_class + s(income) +
             s(monthly_premium_auto, by = employment_status) +
             s(monthly_premium_auto, by = location_code), data = train_df)

y_hat <- predict(mod, newdata = test_df)
summary(mod)

mae <- mean_abs_err(y_hat, test_df$total_claim_amount)
print(paste("MAE of:", round(mae, 2)))
```
Default GAM does worse during cross-validation! Not too surprising when you see the plots though as they look very linear. Although I could also be doing something wrong...


## Quantile regression
Since we are aiming the minimize the mean absolute error. Perhaps fitting a linear model using median regression will likely perform better. This is optimal for minimizing mean absolute error, whereas the mean is optimal for the squared error loss function.

```{r}
mod <- rq(total_claim_amount ~ vehicle_class + income +
     employment_status*monthly_premium_auto + 
     location_code*monthly_premium_auto, data = train_df)

y_hat <- predict(mod, newdata = test_df)

summary.rq(mod, se = "boot")  # bootstrap se estimates

mae <- mean_abs_err(y_hat, test_df$total_claim_amount)
print(paste("MAE of:", round(mae, 2)))
```
This performs a lot better. We should be able to simplify things further based on the zero coefficients above.

Note that here we use the pairwise bootstrap estimate of the standard errors. This is more robust to heteroscadasticity than the standard method (e.g. see [this paper](https://www.tandfonline.com/doi/pdf/10.1198/106186005X27563?needAccess=true)). We can see that we have heteroscadasticity here:
```{r}
plot(test_df$monthly_premium_auto, (y_hat-test_df$total_claim_amount),
     xlab = "monthly_premium_auto", ylab = "rediduals")
```

We will slim things down and simplify the model to make a final model:

## Final Model
Simplify using the following:

- Simplify `employment_status` into a boolean `is_employed`, as being unemployed was the only significant factor level.

- Drop income and vehicle class

```{r}
train_df_simple <- train_df %>%
  mutate(is_unemployed = employment_status == "Unemployed") %>%
  select(-employment_status, -income, -vehicle_class)

test_df_simple <- test_df %>%
  mutate(is_unemployed = employment_status == "Unemployed") %>%
  select(-employment_status, -income, -vehicle_class)

head(train_df_simple)
```

Note that these are primary variables identified in the EDA. We observed that the factor variables `is_unemployed` and `location_code` show a strong interaction with the `monthly_premium_auto` variable:
```{r}
train_df %>%
  ggplot(aes(x = monthly_premium_auto, y = total_claim_amount,
             col = location_code)) +
  geom_point()
```

```{r}
train_df_simple %>%
  ggplot(aes(x = monthly_premium_auto, y = total_claim_amount,
             colour = is_unemployed)) +
  geom_point(alpha = 0.5)
```

The final, very simple model, using just three features is below. Including all the interaction terms seems to be important.

```{r}
mod <- rq(total_claim_amount ~ 
            is_unemployed*monthly_premium_auto + 
            location_code*monthly_premium_auto +
            is_unemployed*location_code, data = train_df_simple)

y_hat <- predict(mod, test_df_simple)

sum <- summary.rq(mod, se = "boot")

mae <- mean_abs_err(y_hat, test_df$total_claim_amount)
print(paste("MAE of:", round(mae, 2)))
```

## Interpreting the model

```{r}
coef_df <- as.tibble(sum$coefficients)
coef_df <- bind_cols(feature = rownames(sum$coefficients), coef_df)
coef_df$feature <- str_replace(coef_df$feature, pattern = "TRUE", "")
coef_df$feature <- str_replace(coef_df$feature, pattern = "location_code", "")
coef_df <- coef_df %>%
  mutate(signif = `Pr(>|t|)` < 0.05) %>%
  select(-`t value`, - `Pr(>|t|)`)
coef_df
```


### Weight plot

```{r}
ggplot(coef_df, aes(x = Value, y = feature)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Value - `Std. Error`, xmax = Value + `Std. Error`)) +
  geom_vline(data = NULL, xintercept = 0, linetype="dotted") +
  labs(x = "Coefficient", y = "Feature")
```



First, visualise the main effects of the categorical variables. This is the coefficients associated with the categorical variables:
```{r}
cat_effects <- tibble(feature = names(mod$coefficients), coefficients = mod$coefficients)
cat_effects$feature <- str_replace(cat_effects$feature, pattern = "TRUE", "")
cat_effects$feature <- str_replace(cat_effects$feature, pattern = "location_code", "")

cat_features <- c("is_unemployed:Suburban", "is_unemployed:Urban",
                  "Suburban", "Urban", "is_unemployed")

cat_effects
# INCLUDE INTERATIONS HERE

cat_effects$feature <- factor(cat_effects$feature, levels = cat_features)

p1 <- cat_effects[cat_effects$feature %in% cat_features, ] %>%
  ggplot(aes(x = coefficients, y=feature)) +
  geom_col(orientation = "y")  +
  geom_vline(data = NULL, xintercept = 0, linetype="dotted") +
  labs(x = "Effect on total claim amount", y = "Feature")
p1
```

Why do we get this big in


```{r}
non_cat <- effect %>%
  filter(effect != 0)

non_cat$feature <- str_replace(non_cat$feature, pattern = "location_code", "")

non_cat <-  non_cat %>%
  filter(!(feature %in% cat_features), feature != "(Intercept)")


non_cat$feature <-factor(
  non_cat$feature,
  levels = c("monthly_premium_auto:Suburban", "monthly_premium_auto:Urban",
             "is_unemployed:monthly_premium_auto", "monthly_premium_auto"
             )
)


p2 <- ggplot(non_cat) + 
  geom_boxplot(aes(x = effect, y = feature), orientation = "y") +
  labs(x = "Effect on total claim amount", y = "Feature") +
  geom_vline(data = NULL, xintercept = 0, linetype="dotted")
p2
```


The interactions seemed particularly important too:
```{r}
effect <- t(t(mod$x) * mod$coefficients)

effect <- effect %>%
  as_tibble() %>%
  pivot_longer(everything(), names_to = "feature", values_to = "effect") %>%
  mutate(feature = str_replace(feature, "TRUE", ""))


effect$feature <- factor(
  effect$feature,
  levels = unique(effect$feature)[rank(str_length(unique(effect$feature)))],
  ordered = TRUE
)

effect %>%
  filter(effect != 0) %>%
  filter(!(feature %in% cat_features)) %>%
  ggplot(aes(x = effect, y = feature)) +
  geom_boxplot(aes(x = effect), orientation = "y") +
  geom_vline(data = NULL, xintercept = 0, linetype="dotted") +
  labs(x = "Effect on total claim amount")
```




Now we have the best model. I will retrain it on the whole data set. Then this can be used to predict on the test set when it is released:
```{r}
df <- rbind(train_df_simple, test_df_simple)

mod <- rq(total_claim_amount ~ 
            is_unemployed*monthly_premium_auto + 
            location_code*monthly_premium_auto +
            is_unemployed*location_code, data = df)

# Put test data here...
```






