---
title: "Analysis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Imports
```{r message=FALSE}
library(mgcv)
library(tidyverse)
library(caret)
library(mice)


df <- read.csv("data/train_simple.csv", stringsAsFactors = TRUE)
df <- select(df, -coverage)  # Doesn't seem particularly useful
```

## Fit linear regression without imputing income
As lots of the incomes are zero, it makes sense to impute these, as employment status is a categorical variable anyway.
```{r}
res <- lm(total_claim_amount ~ employment_status + location_code + 
             vehicle_class + income + monthly_premium_auto +
             employment_status*monthly_premium_auto + 
             location_code*monthly_premium_auto, data = df)

summary(res)
```

## Impute income variable
```{r results='hide'}
df_big <- read.csv("data/train.csv", stringsAsFactors = TRUE)
df_big <- df_big %>% select(-Country, -Customer)
df_big$Income[df_big$Income == 0] <- NA

imputations <- complete(mice(df_big, method = "pmm", seed=1))

df$income <- imputations$Income
```

```{r}
head(df)
```


## Look at linear regression for baseline
```{r}
res <- lm(total_claim_amount ~ employment_status + location_code + 
             vehicle_class + income + monthly_premium_auto +
             employment_status*monthly_premium_auto + 
             location_code*monthly_premium_auto, data = df)

summary(res)
```
Exactly the same performance, great.

## GAM
Does using a GAM improve performance:

```{r}
res <- gam(total_claim_amount ~ employment_status + location_code + 
             vehicle_class + s(income) +
             s(monthly_premium_auto, by = employment_status) +
             s(monthly_premium_auto, by = location_code), data = df)

summary(res)
```
Hmmm seems to do about the same, but I don't really know what I am doing. Perhaps this is due to the fact that it is mostly linear relationships (from EDA) so these result could be reasonable.

## Things to do
See if we can get GAMs to work better. Calculate cross-validation absolute error for each model.  Consider robust regression or quantreg as we are interested in absolute error, rather than the mean square error. [Median regression](https://cran.r-project.org/web/packages/quantreg/vignettes/rq.pdf) is a thing. This will probably work better for absolute error?



